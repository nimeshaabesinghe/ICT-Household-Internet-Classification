# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uRbQ6puZypAXVwjxL4BR9W59dqi0bBW2
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, roc_curve

from xgboost import XGBClassifier
import shap

df = pd.read_excel("Countrywide ICT Survey Database.xlsx", engine="openpyxl")

print("Original Shape:", df.shape)
df.head()

# Keep only useful columns
selected_columns = [
    "Category",   # Urban/Rural
    "District",
    "4. Sex",
    "5. Age(as at last birthday)",
    "9. Level of education",
    "10. Employment status",
    "Smart phones_Home",
    "Laptop_Home",
    "Internet_Home"   # TARGET
]

df = df[selected_columns]

df = df.dropna()

print("After cleaning:", df.shape)

sns.countplot(x=df["Internet_Home"])
plt.title("Distribution of Internet Access")
plt.xticks([0,1], ["No Internet", "Has Internet"])
plt.ylabel("Number of Households")
plt.show()

df = df.sample(n=15000, random_state=42)
print("Reduced Shape:", df.shape)

le = LabelEncoder()

for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = le.fit_transform(df[col])

X = df.drop("Internet_Home", axis=1)
y = df["Internet_Home"]

X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp
)

print("Training size:", X_train.shape)
print("Validation size:", X_val.shape)
print("Test size:", X_test.shape)

model = XGBClassifier(
    n_estimators=200,
    max_depth=5,
    learning_rate=0.1,
    random_state=42
)

model.fit(X_train, y_train)

val_pred = model.predict(X_val)
val_prob = model.predict_proba(X_val)[:,1]

print("Validation Accuracy:", accuracy_score(y_val, val_pred))
print("Validation F1:", f1_score(y_val, val_pred))
print("Validation AUC:", roc_auc_score(y_val, val_prob))

y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:,1]

print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("Test F1 Score:", f1_score(y_test, y_pred))
print("Test AUC Score:", roc_auc_score(y_test, y_prob))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

fpr, tpr, _ = roc_curve(y_test, y_prob)

plt.plot(fpr, tpr)
plt.plot([0,1],[0,1],'--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.show()

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: {:.2f}%".format(accuracy * 100))

explainer = shap.Explainer(model)
shap_values = explainer(X_test)

shap.summary_plot(shap_values, X_test)

import matplotlib.pyplot as plt
from xgboost import plot_importance

plot_importance(model)
plt.title("Feature Importance")
plt.show()

import joblib

joblib.dump(model, "internet_model.pkl")

from google.colab import files
files.download("internet_model.pkl")